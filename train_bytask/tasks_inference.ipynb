{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "cuda_avail = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda_avail else \"cpu\")\n",
    "cerealsModel = torch.load(\"./trained/tasks/cereals_epoch20_2020-04-07.pkl\", map_location=torch.device(device))\n",
    "coffeeModel = torch.load(\"./trained/tasks/coffee_epoch30_2020-04-07.pkl\", map_location=torch.device(device))\n",
    "friedeggModel = torch.load(\"./trained/tasks/friedegg_epoch30_2020-04-07.pkl\", map_location=torch.device(device))\n",
    "juiceModel = torch.load(\"./trained/tasks/juice_epoch40_2020-04-07.pkl\", map_location=torch.device(device))\n",
    "milkModel = torch.load(\"./trained/tasks/milk_epoch40_2020-04-07.pkl\", map_location=torch.device(device))\n",
    "pancakeModel = torch.load(\"./trained/tasks/pancake_epoch40_2020-04-07.pkl\", map_location=torch.device(device))\n",
    "salatModel = torch.load(\"./trained/tasks/salat_epoch30_2020-04-07.pkl\", map_location=torch.device(device))\n",
    "sandwichModel = torch.load(\"./trained/tasks/sandwich_epoch10_2020-04-07.pkl\", map_location=torch.device(device))\n",
    "scrambledeggModel = torch.load(\"./trained/tasks/scrambledegg_epoch40_2020-04-07.pkl\", map_location=torch.device(device))\n",
    "teaModel = torch.load(\"./trained/tasks/tea_epoch10_2020-04-07.pkl\", map_location=torch.device(device))\n",
    "\n",
    "modelDictionary = {\n",
    "    \"cereals\" : cerealsModel,\n",
    "    \"coffee\" : coffeeModel,\n",
    "    \"friedegg\" : friedeggModel,\n",
    "    \"juice\" : juiceModel,\n",
    "    \"milk\" : milkModel,\n",
    "    \"pancake\" : pancakeModel,\n",
    "    \"salat\" : salatModel,\n",
    "    \"sandwich\" : sandwichModel,\n",
    "    \"scrambledegg\" : scrambledeggModel,\n",
    "    \"tea\" : teaModel\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pickle\n",
    "def loadDict(filename):\n",
    "    pkl_file = open(filename, 'rb')\n",
    "    dict = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return dict\n",
    "\n",
    "cerealsMapping = loadDict(\"./trained/tasks/dictionary/cereals.pkl\")\n",
    "coffeeMapping = loadDict(\"./trained/tasks/dictionary/coffee.pkl\")\n",
    "friedeggMapping = loadDict(\"./trained/tasks/dictionary/friedegg.pkl\")\n",
    "juiceMapping = loadDict(\"./trained/tasks/dictionary/juice.pkl\")\n",
    "milkMapping = loadDict(\"./trained/tasks/dictionary/milk.pkl\")\n",
    "pancakeMapping = loadDict(\"./trained/tasks/dictionary/pancake.pkl\")\n",
    "salatMapping = loadDict(\"./trained/tasks/dictionary/salat.pkl\")\n",
    "sandwichMapping = loadDict(\"./trained/tasks/dictionary/sandwich.pkl\")\n",
    "scrambledeggMapping = loadDict(\"./trained/tasks/dictionary/scrambledegg.pkl\")\n",
    "teaMapping = loadDict(\"./trained/tasks/dictionary/tea.pkl\")\n",
    "\n",
    "mappingDictionary = {\n",
    "    \"cereals\" : cerealsMapping,\n",
    "    \"coffee\" : coffeeMapping,\n",
    "    \"friedegg\" : friedeggMapping,\n",
    "    \"juice\" : juiceMapping,\n",
    "    \"milk\" : milkMapping,\n",
    "    \"pancake\" : pancakeMapping,\n",
    "    \"salat\" : salatMapping,\n",
    "    \"sandwich\" : sandwichMapping,\n",
    "    \"scrambledegg\" : scrambledeggMapping,\n",
    "    \"tea\" : teaMapping\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Finish Load the Test data!!!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from utils.read_datasetBreakfast import load_testdata\n",
    "import os\n",
    "\n",
    "COMP_PATH = ''\n",
    "\n",
    "test_split  =  os.path.join(COMP_PATH, 'splits/test.split1.bundle') #Test Split\n",
    "DATA_folder =  os.path.join(COMP_PATH, 'Data/') #Frame I3D features for all videos\n",
    "data_feat = load_testdata(test_split, DATA_folder)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "segment_idx = []\n",
    "with open(\"./utils/test_segment.txt\") as f:\n",
    "    while True:\n",
    "        line = f.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        segment_idx.append(line[:-1].split(\" \"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_feat_seg = []\n",
    "for i in range(len(data_feat)):\n",
    "    videoFrames = []\n",
    "    for j in range(len(segment_idx[i])-1):\n",
    "        videoFrames.append(data_feat[i][1][int(segment_idx[i][j]):int(segment_idx[i][j+1])])\n",
    "    data_feat_seg.append((data_feat[i][0], videoFrames))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_max_prob_seg_seq(outputs, prob_mat, device):\n",
    "    # 48\n",
    "    action_nums = prob_mat.shape[0]\n",
    "    f = torch.zeros(len(outputs), action_nums).to(device)\n",
    "    record = torch.zeros(len(outputs), action_nums).to(device).long()\n",
    "\n",
    "    for i, i_prob in enumerate(outputs):\n",
    "        if i == 0:\n",
    "            f[i] = i_prob\n",
    "        else:\n",
    "            for j in range(action_nums):\n",
    "                last_to_j_max_prob, last_j = torch.max(f[i-1] + torch.log(prob_mat[:, j]), 0)\n",
    "                f[i][j] = last_to_j_max_prob + i_prob[j]\n",
    "                # print(last_to_j_max_prob, i_prob[j])\n",
    "                record[i][j] = last_j\n",
    "        # f[i] = normalize(f[i],dim=0)\n",
    "\n",
    "    # get final max prob\n",
    "    max_final_prob, max_final_action = torch.max(f[len(outputs)-1], 0)\n",
    "\n",
    "    # get max prob seq\n",
    "    seq = [max_final_action.item()]\n",
    "    for k in reversed(range(1, len(outputs))):\n",
    "        last_action = record[k][max_final_action]\n",
    "        seq.append(last_action.item())\n",
    "        max_final_action = last_action\n",
    "    \n",
    "    seq.reverse()\n",
    "    return seq\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-9480eba5f539>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[1;31m#print(task +\" : \"+ str(original_label))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mseg_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mnew_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_max_prob_seg_seq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseg_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob_mat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" : \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-4a22d31ba600>\u001b[0m in \u001b[0;36mget_max_prob_seg_seq\u001b[1;34m(outputs, prob_mat, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_nums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[0mlast_to_j_max_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_j\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlast_to_j_max_prob\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                 \u001b[1;31m# print(last_to_j_max_prob, i_prob[j])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mrecord\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlast_j\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ],
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from Dataset.SegmentDataset import SegmentDataset\n",
    "import torch.utils.data as tud\n",
    "\n",
    "batch_size = 1\n",
    "outputs = []\n",
    "prob_mat = torch.load('./trained/conv/prob_mat_next.pt', map_location=torch.device(device))\n",
    "for i in data_feat_seg:\n",
    "    task = i[0]\n",
    "    fake_labels = np.ones(len(i[1]))\n",
    "    test_dataset = SegmentDataset(i[1], fake_labels, seed = 2)\n",
    "    test_dataloader = tud.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    labelMapping = mappingDictionary[task]\n",
    "    label_nums = len(labelMapping)\n",
    "    model = modelDictionary[task].to(device)\n",
    "    model.eval()\n",
    "    seg_labels = []\n",
    "    for x, labels in test_dataloader:\n",
    "        x = x.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(x).to(device)\n",
    "            output = output.view(-1, label_nums)\n",
    "            predict_label = torch.max(output, 1)[1]\n",
    "            original_label = labelMapping[predict_label.item()]\n",
    "            #print(task +\" : \"+ str(original_label))\n",
    "            seg_labels.append(original_label)\n",
    "    new_labels = get_max_prob_seg_seq(seg_labels, prob_mat, device)\n",
    "    print(task + \" : \" + str(new_labels))\n",
    "    outputs += new_labels\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "1284\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(len(outputs))\n",
    "            "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "path = './results/tasks/test_result_bytask.csv'\n",
    "f = open(path, 'w+')\n",
    "f.write('Id,Category\\n')\n",
    "\n",
    "counter = 0\n",
    "for i in outputs:\n",
    "        f.write(f'{counter},{i}\\n')\n",
    "        counter += 1\n",
    "f.close()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}