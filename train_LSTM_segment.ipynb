{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Finish Load the Training data and labels!!!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from utils.read_datasetBreakfast import load_data, read_mapping_dict\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "COMP_PATH = ''\n",
    "\n",
    "''' \n",
    "training to load train set\n",
    "test to load test set\n",
    "'''\n",
    "split = 'training'\n",
    "#split = 'test'\n",
    "train_split =  os.path.join(COMP_PATH, 'splits/train.exclude_val.bundle') #Train Split\n",
    "test_split  =  os.path.join(COMP_PATH, 'splits/test.split1.bundle') #Test Split\n",
    "GT_folder   =  os.path.join(COMP_PATH, 'groundTruth/') #Ground Truth Labels for each training video \n",
    "DATA_folder =  os.path.join(COMP_PATH, 'Data/') #Frame I3D features for all videos\n",
    "mapping_loc =  os.path.join(COMP_PATH, 'splits/mapping_bf.txt') \n",
    "\n",
    "actions_dict = read_mapping_dict(mapping_loc)\n",
    "\n",
    "data_feat, data_labels = load_data( train_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Finish Load the Training data and labels!!!\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "validation_split = os.path.join(COMP_PATH, 'splits/val.split1.bundle') #Validation split\n",
    "val_data_feat, val_data_labels = load_data( validation_split, actions_dict, GT_folder, DATA_folder, datatype = split) #Get features and labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import torch\n",
    "def splitByFrames(data_feat, data_labels, frames_per_clip):\n",
    "    new_data_feat = []\n",
    "    new_data_labels = []\n",
    "    for i in range(0, len(data_feat)):\n",
    "        total_frames, dim = data_feat[i].shape\n",
    "        segment = data_feat[i]\n",
    "        if total_frames % frames_per_clip != 0:\n",
    "            pad_num = frames_per_clip - total_frames % frames_per_clip\n",
    "            pad_Tensor = torch.zeros((pad_num, 400), dtype=torch.float64)\n",
    "            segment = torch.cat((segment, pad_Tensor))\n",
    "        total_frames, dim = segment.shape\n",
    "        clip_num = int(total_frames / frames_per_clip)\n",
    "        clips = segment.view(-1, frames_per_clip, 400)\n",
    "    \n",
    "        label = data_labels[i]\n",
    "        new_data_labels += [label] * clip_num\n",
    "        new_data_feat.append(clips)\n",
    "\n",
    "    new_data_feat = torch.cat(new_data_feat)\n",
    "    return new_data_feat, new_data_labels\n",
    "\n",
    "new_data_feat, new_data_labels = splitByFrames(data_feat, data_labels, 16)\n",
    "val_data_feat, val_data_labels = splitByFrames(val_data_feat, val_data_labels, 16)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from Dataset.VideoDataset import VideoDataset\n",
    "import torch.utils.data as tud\n",
    "from Models.LSTM import LSTM_Model\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "epochs = 10\n",
    "batch_size = 50\n",
    "\n",
    "dataset = VideoDataset(new_data_feat, new_data_labels)\n",
    "dataloader = tud.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = LSTM_Model()\n",
    "learning_rate = 1e-3\n",
    "log_interval = 200\n",
    "\n",
    "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    scores = []\n",
    "    for batch_idx, (in_feature, label) in enumerate(train_loader):\n",
    "        in_feature = in_feature.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(in_feature)\n",
    "        loss = F.cross_entropy(output, label)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        label_predict = torch.max(output, 1)[1]\n",
    "        step_score = accuracy_score(label.cpu().data.squeeze().numpy(), label_predict.cpu().data.squeeze().numpy())\n",
    "        scores.append(step_score)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx + 1) % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accu: {:.2f}%'.format(\n",
    "                epoch + 1, (batch_idx+1)*batch_size, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item(), 100 * step_score))\n",
    "        \n",
    "    return losses, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "val_dataset = VideoDataset(val_data_feat, val_data_labels)\n",
    "val_dataloader = tud.DataLoader(val_dataset, batch_size= batch_size, shuffle=True)\n",
    "\n",
    "def validation(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    all_labels = []\n",
    "    all_labels_predict = []\n",
    "    with torch.no_grad():\n",
    "        for in_feature, labels in test_loader:\n",
    "            in_feature = in_feature.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = model(in_feature)\n",
    "            loss = F.cross_entropy(output, labels)\n",
    "            test_loss += loss.item()\n",
    "            labels_predict = torch.max(output, 1)[1]\n",
    "            all_labels.extend(labels)\n",
    "            all_labels_predict.extend(labels_predict)\n",
    "            \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    # compute accuracy\n",
    "    all_labels = torch.stack(all_labels, dim=0)\n",
    "    all_labels_predict = torch.stack(all_labels_predict, dim=0)\n",
    "    test_score = accuracy_score(all_labels.cpu().data.squeeze().numpy(), all_labels_predict.cpu().data.squeeze().numpy())\n",
    "    print('\\nTest set ({:d} samples): Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(len(all_labels), test_loss, 100* test_score))\n",
    "    \n",
    "    return test_loss, test_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Train Epoch: 1 [10000/146292 (7%)]\tLoss: 3.091752, Accu: 14.00%\n",
      "Train Epoch: 1 [20000/146292 (14%)]\tLoss: 2.869417, Accu: 20.00%\n",
      "Train Epoch: 1 [30000/146292 (21%)]\tLoss: 2.814002, Accu: 22.00%\n",
      "Train Epoch: 1 [40000/146292 (27%)]\tLoss: 2.535698, Accu: 24.00%\n",
      "Train Epoch: 1 [50000/146292 (34%)]\tLoss: 2.557809, Accu: 24.00%\n",
      "Train Epoch: 1 [60000/146292 (41%)]\tLoss: 2.352424, Accu: 20.00%\n",
      "Train Epoch: 1 [70000/146292 (48%)]\tLoss: 1.964300, Accu: 44.00%\n",
      "Train Epoch: 1 [80000/146292 (55%)]\tLoss: 2.134269, Accu: 38.00%\n",
      "Train Epoch: 1 [90000/146292 (62%)]\tLoss: 2.048891, Accu: 36.00%\n",
      "Train Epoch: 1 [100000/146292 (68%)]\tLoss: 2.216703, Accu: 38.00%\n",
      "Train Epoch: 1 [110000/146292 (75%)]\tLoss: 2.221876, Accu: 32.00%\n",
      "Train Epoch: 1 [120000/146292 (82%)]\tLoss: 2.377602, Accu: 34.00%\n",
      "Train Epoch: 1 [130000/146292 (89%)]\tLoss: 1.912910, Accu: 38.00%\n",
      "Train Epoch: 1 [140000/146292 (96%)]\tLoss: 1.938234, Accu: 42.00%\n",
      "\n",
      "Test set (34543 samples): Average loss: 0.0489, Accuracy: 32.19%\n",
      "\n",
      "Train Epoch: 2 [10000/146292 (7%)]\tLoss: 2.224126, Accu: 38.00%\n",
      "Train Epoch: 2 [20000/146292 (14%)]\tLoss: 2.175358, Accu: 42.00%\n",
      "Train Epoch: 2 [30000/146292 (21%)]\tLoss: 2.162483, Accu: 30.00%\n",
      "Train Epoch: 2 [40000/146292 (27%)]\tLoss: 2.152801, Accu: 48.00%\n",
      "Train Epoch: 2 [50000/146292 (34%)]\tLoss: 1.782191, Accu: 40.00%\n",
      "Train Epoch: 2 [60000/146292 (41%)]\tLoss: 2.117380, Accu: 36.00%\n",
      "Train Epoch: 2 [70000/146292 (48%)]\tLoss: 2.197668, Accu: 32.00%\n",
      "Train Epoch: 2 [80000/146292 (55%)]\tLoss: 1.635640, Accu: 50.00%\n",
      "Train Epoch: 2 [90000/146292 (62%)]\tLoss: 2.091395, Accu: 44.00%\n",
      "Train Epoch: 2 [100000/146292 (68%)]\tLoss: 1.691962, Accu: 48.00%\n",
      "Train Epoch: 2 [110000/146292 (75%)]\tLoss: 2.327256, Accu: 34.00%\n",
      "Train Epoch: 2 [120000/146292 (82%)]\tLoss: 1.944854, Accu: 46.00%\n",
      "Train Epoch: 2 [130000/146292 (89%)]\tLoss: 1.599466, Accu: 52.00%\n",
      "Train Epoch: 2 [140000/146292 (96%)]\tLoss: 2.358985, Accu: 32.00%\n",
      "\n",
      "Test set (34543 samples): Average loss: 0.0481, Accuracy: 34.20%\n",
      "\n",
      "Train Epoch: 3 [10000/146292 (7%)]\tLoss: 1.924748, Accu: 44.00%\n",
      "Train Epoch: 3 [20000/146292 (14%)]\tLoss: 2.010519, Accu: 46.00%\n",
      "Train Epoch: 3 [30000/146292 (21%)]\tLoss: 1.861397, Accu: 38.00%\n",
      "Train Epoch: 3 [40000/146292 (27%)]\tLoss: 1.656012, Accu: 52.00%\n",
      "Train Epoch: 3 [50000/146292 (34%)]\tLoss: 1.873965, Accu: 50.00%\n",
      "Train Epoch: 3 [60000/146292 (41%)]\tLoss: 1.734332, Accu: 54.00%\n",
      "Train Epoch: 3 [70000/146292 (48%)]\tLoss: 1.561513, Accu: 56.00%\n",
      "Train Epoch: 3 [80000/146292 (55%)]\tLoss: 1.534391, Accu: 46.00%\n",
      "Train Epoch: 3 [90000/146292 (62%)]\tLoss: 2.129880, Accu: 38.00%\n",
      "Train Epoch: 3 [100000/146292 (68%)]\tLoss: 1.809351, Accu: 50.00%\n",
      "Train Epoch: 3 [110000/146292 (75%)]\tLoss: 1.815392, Accu: 52.00%\n",
      "Train Epoch: 3 [120000/146292 (82%)]\tLoss: 1.958790, Accu: 40.00%\n",
      "Train Epoch: 3 [130000/146292 (89%)]\tLoss: 2.198167, Accu: 38.00%\n",
      "Train Epoch: 3 [140000/146292 (96%)]\tLoss: 1.942641, Accu: 48.00%\n",
      "\n",
      "Test set (34543 samples): Average loss: 0.0470, Accuracy: 34.24%\n",
      "\n",
      "Train Epoch: 4 [10000/146292 (7%)]\tLoss: 1.162117, Accu: 70.00%\n",
      "Train Epoch: 4 [20000/146292 (14%)]\tLoss: 1.597744, Accu: 50.00%\n",
      "Train Epoch: 4 [30000/146292 (21%)]\tLoss: 1.691358, Accu: 50.00%\n",
      "Train Epoch: 4 [40000/146292 (27%)]\tLoss: 1.595717, Accu: 52.00%\n",
      "Train Epoch: 4 [50000/146292 (34%)]\tLoss: 1.840617, Accu: 50.00%\n",
      "Train Epoch: 4 [60000/146292 (41%)]\tLoss: 1.682169, Accu: 46.00%\n",
      "Train Epoch: 4 [70000/146292 (48%)]\tLoss: 1.544012, Accu: 58.00%\n",
      "Train Epoch: 4 [80000/146292 (55%)]\tLoss: 1.437928, Accu: 58.00%\n",
      "Train Epoch: 4 [90000/146292 (62%)]\tLoss: 1.297730, Accu: 54.00%\n",
      "Train Epoch: 4 [100000/146292 (68%)]\tLoss: 1.653017, Accu: 46.00%\n",
      "Train Epoch: 4 [110000/146292 (75%)]\tLoss: 1.765556, Accu: 52.00%\n",
      "Train Epoch: 4 [120000/146292 (82%)]\tLoss: 1.843291, Accu: 54.00%\n",
      "Train Epoch: 4 [130000/146292 (89%)]\tLoss: 1.499567, Accu: 48.00%\n",
      "Train Epoch: 4 [140000/146292 (96%)]\tLoss: 1.617079, Accu: 62.00%\n",
      "\n",
      "Test set (34543 samples): Average loss: 0.0491, Accuracy: 35.00%\n",
      "\n",
      "Train Epoch: 5 [10000/146292 (7%)]\tLoss: 2.147953, Accu: 50.00%\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-08c3b7992bdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtrain_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mtest_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-88d9dde1bfad>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(log_interval, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0min_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0min_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0min_feature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "cuda_avail = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda_avail else \"cpu\")\n",
    "\n",
    "lstm = LSTM_Model().double().to(device)\n",
    "optimizer = torch.optim.Adam(list(lstm.parameters()), lr=learning_rate)\n",
    "\n",
    "# record training process\n",
    "epoch_train_losses = []\n",
    "epoch_train_scores = []\n",
    "epoch_test_losses = []\n",
    "epoch_test_scores = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses, train_scores = train(log_interval, lstm, device, dataloader, optimizer, epoch)\n",
    "    test_losses, test_score = validation(lstm, device, val_dataloader)\n",
    "    \n",
    "    epoch_train_losses.append(train_losses)\n",
    "    epoch_train_scores.append(train_scores)\n",
    "    epoch_test_losses.append(test_losses)\n",
    "    epoch_test_scores.append(test_score)\n",
    "\n",
    "torch.save(model.state_dict(), \"./trained/lstm.pt\")\n",
    "A = np.array(epoch_train_losses)\n",
    "B = np.array(epoch_train_scores)\n",
    "C = np.array(epoch_test_losses)\n",
    "D = np.array(epoch_test_scores)\n",
    "np.save('./results/lstm/training_losses_2.npy', A)\n",
    "np.save('./results/lstm/training_scores_2.npy', B)\n",
    "np.save('./results/lstm/test_loss.npy', C)\n",
    "np.save('./results/lstm/test_score.npy', D)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2020-03-28\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now().date())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "#plt.plot(np.arange(1, epochs + 1), A[:, -1])  # train loss (on epoch end)\n",
    "plt.plot(A.flatten())  # train loss (on epoch end)\n",
    "#plt.plot(np.arange(1, epochs + 1), C)  \n",
    "plt.title(\"model loss\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train','test'], loc=\"upper left\")\n",
    "# 2nd figure\n",
    "plt.subplot(122)\n",
    "#plt.plot(np.arange(1, epochs + 1), B[:, -1])\n",
    "plt.plot(B.flatten())\n",
    "\n",
    "#plt.plot(np.arange(1, epochs + 1), D) # train accuracy (on epoch end)\n",
    "plt.title(\"training scores\")\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train', 'test'], loc=\"upper left\")\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}